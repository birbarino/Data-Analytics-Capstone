{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f69726",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c726b",
   "metadata": {},
   "source": [
    "We are wrangling up some data from simulated APT activity that was captured on a mock production network with the efforts of creating a \"realistic, semi-synthetic\" dataset. I will document some of the process that I undertook, as a decent amount of it was exploratory, as well as covering the changes I had to make with the original dataset.\n",
    "\n",
    "To reduce scope, yet still covering both the axes of host and network logs, I will just be wrangling the Netflow data, Linux auth+audit logs, and Windows Security Events.\n",
    "\n",
    "The source for this dataset can be found here: https://doi.org/10.1016/j.comnet.2023.109688\n",
    "\n",
    "The original data/ can be found here: https://www.kaggle.com/datasets/ernie55ernie/unraveled-advanced-persistent-threats-dataset/data\n",
    "\n",
    "Due to the size of the data (835 MB ZIP, decompressed to 4.43 GB of plaintext and binary data) the download will take some time, but I used the following command:\n",
    "\n",
    "```zsh\n",
    "  curl -L -o ~/Downloads/unraveled-advanced-persistent-threats-dataset.zip\\\n",
    "    https://www.kaggle.com/api/v1/datasets/download/ernie55ernie/unraveled-advanced-persistent-threats-dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82017adf",
   "metadata": {},
   "source": [
    "While cleaning up the data, we should keep in mind our hypothesis and trim away anything that probably won't contribute to proving the null or alternative.\n",
    "\n",
    "Hypothesis: Choose one\n",
    "- APTs adjust TTPs in response to defensive measures and signs of detection.\n",
    "- We can better detect APTs based on their TTPs versus specific artifacts\n",
    "  - Testing the highest scoring/most imporant features of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda57cdc",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52354734",
   "metadata": {},
   "source": [
    "Below I threw together a few helper functions to solve a couple problems I ran into when trying to load CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2869178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import chardet\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_encoding(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        raw = f.read(4096)  # read first 4 KB\n",
    "\n",
    "        # Use chardet lib to detect the encoding\n",
    "        result = chardet.detect(raw)\n",
    "\n",
    "        return result['encoding']\n",
    "\n",
    "def get_files_recurse(path):\n",
    "    result = []\n",
    "    \n",
    "    # For each file, append its full path to a list\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            fullpath = os.path.join(root, file)\n",
    "            result.append(fullpath)\n",
    "            \n",
    "    return result\n",
    "\n",
    "def load_all_csv(path, sep=',', recurse=False, verbose=False, encoding='auto'):\n",
    "    files = [path + x for x in os.listdir(path)] if not recurse else get_files_recurse(path)\n",
    "    d = dict()\n",
    "    \n",
    "    # For each file, check its encoding scheme, then store as DF in dict with fullpath as key\n",
    "    for f in files:\n",
    "        if not os.path.isfile(f):\n",
    "            continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f)\n",
    "        \n",
    "        enc = get_encoding(f) if encoding == 'auto' else encoding\n",
    "        d[f] = pd.read_csv(f, delimiter=sep, encoding=enc)\n",
    "        \n",
    "    # Concatenate all DFs in the dictionary, ignoring the indexes so they don't collide\n",
    "    df = pd.concat(d.values(), ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435f586",
   "metadata": {},
   "source": [
    "# Network Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654fcc2",
   "metadata": {},
   "source": [
    "## Netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75944b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/unraveled-apt/network-flows/'\n",
    "\n",
    "df = load_all_csv(path, recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropme = [\n",
    "    # Identifiers\n",
    "    'fgid', 'id', ' id',\n",
    "    \n",
    "    # Redundant and unneeded Layer 2/3 info\n",
    "    'src_oui', 'dst_oui', 'tunnel_id', 'ip_version',\n",
    "    'vlan_id',\n",
    "    \n",
    "    # Sparse application metadata\n",
    "    'requested_server_name', 'client_fingerprint', \n",
    "    'content_type', 'application_is_guessed',\n",
    "    \n",
    "    # Redundant bidirectional stats\n",
    "    'bidirectional_min_ps', 'bidirectional_mean_ps', \n",
    "    'bidirectional_stddev_ps', 'bidirectional_max_ps',\n",
    "    'bidirectional_min_piat_ms', 'bidirectional_mean_piat_ms',\n",
    "    'bidirectional_stddev_piat_ms', 'bidirectional_max_piat_ms',\n",
    "    \n",
    "    # Redundant bidirectional TCP flags (keep directional)\n",
    "    'bidirectional_syn_packets', 'bidirectional_cwr_packets',\n",
    "    'bidirectional_ece_packets', 'bidirectional_urg_packets',\n",
    "    'bidirectional_ack_packets', 'bidirectional_psh_packets',\n",
    "    'bidirectional_rst_packets', 'bidirectional_fin_packets',\n",
    "    \n",
    "    # Potentially redundant timing\n",
    "    'src2dst_last_seen_ms', 'dst2src_last_seen_ms'\n",
    "]\n",
    "\n",
    "reduced_df = df.drop(columns=dropme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28066c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values\n",
    "reduced_df['Signature'] = reduced_df['Signature'].fillna('Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e915259f",
   "metadata": {},
   "source": [
    "Even with dropping a decent amount of columns, we still have a DataFrame that takes up over 6GB of memory. All of the datatypes appear to just be the default `int64`/`object`, so we can make some changes to that and save a fair amount.\n",
    "\n",
    "I applied the methodology commented into the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're only working with whole numbers here.\n",
    "floats = reduced_df.dtypes[reduced_df.dtypes == 'float64'].index\n",
    "reduced_df[floats] = reduced_df[floats].astype('int64')\n",
    "\n",
    "# Storing some frequently referenced sets of values\n",
    "int_cols = reduced_df.dtypes[reduced_df.dtypes == 'int64'].index\n",
    "maxes = reduced_df[int_cols].max()\n",
    "\n",
    "\n",
    "# I used unsigned ints because none of the values are negative.\n",
    "# uint16 = 0-65535\n",
    "uint16 = maxes < 65536\n",
    "uint16 = uint16[uint16].index\n",
    "\n",
    "# uint32 = 0-4294967295\n",
    "uint32 = maxes < 4294967296  # includes uint16 cols, but we will do that type change after this one\n",
    "uint32 = uint32[uint32].index\n",
    "\n",
    "# For these, I manually checked how many nunique() they had, and it was on the lower end.\n",
    "categories = [\n",
    "    'src_ip', 'dst_ip', 'src_mac', \n",
    "    'dst_mac', 'expiration_id', 'application_name', \n",
    "    'user_agent', 'server_fingerprint', 'Activity', \n",
    "    'DefenderResponse', 'Signature', 'Stage',\n",
    "    'application_category_name'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050af375",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df[categories].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df[categories] = reduced_df[categories].astype('category')\n",
    "reduced_df[float32] = reduced_df[float32].astype('float32')\n",
    "reduced_df[uint32] = reduced_df[uint32].astype('uint32')\n",
    "reduced_df[uint16] = reduced_df[uint16].astype('uint16')\n",
    "\n",
    "reduced_df['flow_start'] = pd.to_datetime(reduced_df['bidirectional_first_seen_ms'], unit='ms')\n",
    "reduced_df['flow_end'] = pd.to_datetime(reduced_df['bidirectional_last_seen_ms'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17897244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# lets free up some memory\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move start and end timestamps if they are not already there\n",
    "reduced_df = reduced_df[['flow_start', 'flow_end'] + \n",
    "                        [c for c in reduced_df.columns if c not in ['flow_start', 'flow_end']]]\n",
    "\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as pickle to save all that hard work we did converting datatypes\n",
    "reduced_df.to_pickle('../data/cleaned/netflow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1b02f",
   "metadata": {},
   "source": [
    "These Netflow logs should be ready for us to play around with further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = pd.read_pickle('../data/cleaned/netflow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b8147",
   "metadata": {},
   "source": [
    "# Linux Host Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad0e068",
   "metadata": {},
   "source": [
    "## `audit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.split(os.getcwd())[0] + '/data/unraveled-apt/host-logs/audit/'\n",
    "audit_df = load_all_csv(path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c26e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0cc2f",
   "metadata": {},
   "source": [
    "On the last row, there appears to be some preceeding whitespace in the LogEvent column. Lets handle that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in audit_df.columns:\n",
    "    try:\n",
    "        audit_df[col] = audit_df[col].str.strip()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7f56f",
   "metadata": {},
   "source": [
    "With that out of the way, we will need to address the log message that is sometimes nested under the `msg` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_df.LogEvent.iloc[111]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323482f7",
   "metadata": {},
   "source": [
    "```sh\n",
    "type=USER_START \n",
    "ts=1621862701.432 \n",
    "...\n",
    "# I still want to keep this mostly intact\n",
    "msg=\\'op=PAM:session_open acct=\"root\" exe=\"/usr/sbin/cron\" hostname=? addr=? terminal=cron res=success\\'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ced7eb",
   "metadata": {},
   "source": [
    "I plan to keep this by extracting `msg` out of the string, processing it separately from the rest of the log, then throwing `msg` into the rest of the log as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df = audit_df.LogEvent.str.extract(r\"msg=('.*')\")\n",
    "no_msg = audit_df.LogEvent.str.replace(r\"msg=('.*')\", repl='', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1934a99",
   "metadata": {},
   "source": [
    "This is what we extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70189172",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e40aee",
   "metadata": {},
   "source": [
    "Here is what the `no_msg` series looks like now. We can proceeed with converting this into a DataFrame, then concatenating `msg_df` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00006ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Message removed:\", no_msg.iloc[111])\n",
    "print(\"Original log:   \", audit_df.LogEvent.iloc[111])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe9415",
   "metadata": {},
   "source": [
    "We'll store our final result in a var called `logs`. Very descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = no_msg.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58edeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.iloc[logs.shape[0]-1]  # We are doing it this way because I like how it formats the text better. No judging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_logs = logs.apply(lambda x: {split_field[0]: split_field[1] for split_field in [log_field.split('=') for log_field in x]}).to_dict()\n",
    "list(expand_logs.items())[:2] # logs are expanded to a dictionary of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(expand_logs).T\n",
    "print(log_df.head(6))\n",
    "\n",
    "del expand_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470086f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.columns  # no msg column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a36bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df['ts'] = pd.to_datetime(log_df['ts'].str.replace('.', ''), unit='ms')\n",
    "log_df['ts'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of labeled audit log data\n",
    "labeled_audit_df = pd.concat([\n",
    "        msg_df,  # contains the retained msg field\n",
    "        log_df,  # contains the rest of the log, parsed\n",
    "        audit_df[audit_df.columns[1:]]  # slice off first column, since we just expanded that.\n",
    "        # This will give us LogEvent expanded out into more columns as well as the labels.\n",
    "    ], \n",
    "    axis=1)\n",
    "\n",
    "labeled_audit_df.rename({0: 'msg'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11087099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering the columns to put the msg field in position 11\n",
    "labeled_audit_df = labeled_audit_df[labeled_audit_df.columns[1:].insert(11, 'msg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60882857",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_audit_df['Signature'] = labeled_audit_df['Signature'].fillna('Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save a lot of memory just by changing some columns to type 'category'\n",
    "categories = labeled_audit_df.columns[labeled_audit_df.nunique() < 100]\n",
    "labeled_audit_df[categories] = labeled_audit_df[categories].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over half the values in each of these columns == null\n",
    "dropme = labeled_audit_df.columns[labeled_audit_df.notna().sum() / labeled_audit_df.shape[0] < 0.50]\n",
    "dropme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f761940",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_audit_df.drop(columns=dropme, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7420b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_audit_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_audit_df[['pid', 'ses']] = labeled_audit_df[['pid', 'ses']].fillna(0)\n",
    "\n",
    "labeled_audit_df.pid = labeled_audit_df.pid.astype('uint32')\n",
    "labeled_audit_df.tsid = labeled_audit_df.tsid.astype('uint32')\n",
    "labeled_audit_df.ses = labeled_audit_df.ses.astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our work to save me some time.\n",
    "labeled_audit_df.to_pickle('../data/cleaned/audit.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dedee5",
   "metadata": {},
   "source": [
    "## `auth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb61670",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.split(os.getcwd())[0] + '/data/unraveled-apt/host-logs/auth/'\n",
    "auth_df = load_all_csv(path, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d6272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in auth_df.columns[1:]:\n",
    "    print(auth_df[col].value_counts(), end=f'\\n{'-'*20}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_df.LogEvent.iloc[[5, 10, 15, 20, 25, 100, 200, 300, 1000, 2000]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01297300",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = auth_df.LogEvent.apply(lambda x: x.split(' ', maxsplit=5))\n",
    "logs.head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=logs.tolist(), columns=['month', 'day', 'time', 'hostname', 'app', 'msg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ts'] = \"2021-\"+df['month']+\"-\"+df['day']+\" \"+df['time']\n",
    "df['ts'] = pd.to_datetime(df['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b7704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant date cols and make ts col 0\n",
    "df.drop(['month', 'day', 'time'], axis=1, inplace=True, errors='ignore')\n",
    "df = df[df.columns[:-1].insert(0, 'ts')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df['app'].str.split('[')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c530fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.apply(lambda x: [e.strip(']:') for e in x])\n",
    "tmp = tmp.apply(lambda x: x+[0] if len(x) == 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8f605",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c99798",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(tmp.tolist(), columns=['app','pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6196c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a08c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['app'] = tmp['app']\n",
    "df['pid'] = tmp['pid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8354f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ts','hostname','app','pid','msg']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed406c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.msg = df.msg.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.columns[df.nunique() < 100]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c47919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categories] = df[categories].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033627f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pid = df.pid.astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f6f8f",
   "metadata": {},
   "source": [
    "Now to finally add the labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a014725",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = auth_df.columns[1:]\n",
    "df[labels] = auth_df[labels].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288eedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/cleaned/auth.pkl')\n",
    "\n",
    "import gc\n",
    "\n",
    "del df, auth_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b24441",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0231007",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_linux_host_df = pd.concat([audit_df, auth_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_linux_host_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7faa232",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d6b18",
   "metadata": {},
   "source": [
    "# Windows Host Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee428c3",
   "metadata": {},
   "source": [
    "## Security.evtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_all_csv(path='../data/unraveled-apt/host-logs/windows/', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda30d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Signature'] = df['Signature'].fillna('Normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c97da",
   "metadata": {},
   "source": [
    "Perusing through the data seems to show that the cleaning messed up event ID 4625, as it was probably formatted slightly differently. We'll fix this just by using `fillna` and moving some columns around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b682c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[df.EventID == 4625].copy()\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.LogMessage = tmp.Activity\n",
    "tmp.Activity = tmp.Activity.apply(lambda x:\"Normal\")\n",
    "tmp[['Stage', 'DefenderResponse']] = tmp[['Stage', 'DefenderResponse']].fillna('Benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256b31d",
   "metadata": {},
   "source": [
    "There we go, that looks better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.EventID == 4625] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44250bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.EventID == 4625].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74614531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2543fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe602c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DateTime = pd.to_datetime(df.DateTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.columns[df.nunique() < 1000]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categories] = df[categories].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23670a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.LogMessage.isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd58d2b2",
   "metadata": {},
   "source": [
    "Let's check both of the NaN fields to make sure they only contain nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dddefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.LogMessage.isna()][['Signature', 'LogMessage']].isna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb779fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/cleaned/win-security.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7390a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/cleaned/win-security.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
